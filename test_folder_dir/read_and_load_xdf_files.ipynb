{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1510057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyxdf\n",
    "import mne\n",
    "from mne.datasets import misc\n",
    "import os\n",
    "import time\n",
    "from pyxdf import match_streaminfos, resolve_streams\n",
    "from mnelab.io.xdf import read_raw_xdf\n",
    "import json\n",
    "import csv\n",
    "import pybv\n",
    "from bids_validator import BIDSValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f38d3",
   "metadata": {},
   "source": [
    "## Check for existence of a new xdf file in the directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b15faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_new_file(folder_path, last_checked_file_path):\n",
    "    \"\"\"\n",
    "    Checks for new files in a multilevel folder structure.\n",
    "    \n",
    "    Parameters:\n",
    "        root_dir (str): The root directory to search for new files.\n",
    "        last_checked_time (float): The last checked time in seconds since the epoch.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of new file paths.\n",
    "    \"\"\"\n",
    "    # Retrieve the last checked time from the file\n",
    "    try:\n",
    "        with open(last_checked_file_path, 'r') as f:\n",
    "            last_checked_time = float(f.readlines()[-1].strip())\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        last_checked_time = 0.0\n",
    "    \n",
    "\n",
    "    # Check for new files\n",
    "    new_files = []\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            if os.path.getmtime(file_path) > last_checked_time:\n",
    "                new_files.append(file_path)\n",
    "    \n",
    "    # Save the current time to the file\n",
    "    with open(last_checked_file_path, 'a') as f:\n",
    "        f.write(str(time.time()) + '\\n')\n",
    "        \n",
    "    \n",
    "    return new_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900a814b",
   "metadata": {},
   "source": [
    "## Load the xdf file from the given path and get its streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e74c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_streams(xdf_path):\n",
    "    streams = resolve_streams(xdf_path)\n",
    "    stream_names = [streams[i]['name'] for i in range(len(streams))]\n",
    "    return stream_names,streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c505a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_xdf(xdf_path,streams):\n",
    "    # Get the stream id of the EEG stream\n",
    "    stream_id = match_streaminfos(streams, [{\"type\": \"EEG\"}])[0]\n",
    "    raw = read_raw_xdf(xdf_path,stream_ids=[stream_id])\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda47cb3",
   "metadata": {},
   "source": [
    "### Create the Metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50fa3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_participants_json(file_path):\n",
    "    data = {\n",
    "        \"pInfoDesc\": {\n",
    "            \"participant_id\": {\n",
    "                \"Description\": \"Unique participant identifier\"\n",
    "            },\n",
    "            \"gender\": {\n",
    "                \"Description\": \"Sex of participant\",\n",
    "                \"Levels\": {\n",
    "                    \"M\": \"Male\",\n",
    "                    \"F\": \"Female\"\n",
    "                }\n",
    "            },\n",
    "            \"age\": {\n",
    "                \"Description\": \"Age of participant\",\n",
    "                \"Units\": \"Years\"\n",
    "            },\n",
    "            \"handedness\": {\n",
    "                \"Description\": \"Handedness of participant\",\n",
    "                \"Levels\": {\n",
    "                    \"R\": \"Right\",\n",
    "                    \"L\": \"Left\"\n",
    "                }\n",
    "            },\n",
    "            \"vision\": {\n",
    "                \"Description\": \"Vision of participant\",\n",
    "                \"Levels\": {\n",
    "                    \"N\": \"Normal\",\n",
    "                    \"C\": \"Corrected\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    file = file_path + '/participants.json'\n",
    "    with open(file, \"w\") as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "    return file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebec7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eeg_json(file_path):\n",
    "    tInfo = {\n",
    "        \"InstitutionName\": \"University of Stuttgart\",\n",
    "        \"InstitutionAddress\": \"Universitätsstraße 34, 70569 Stuttgart, GER\",\n",
    "        \"InstitutionalDepartmentName\": \"Computational Cognitive Science\",\n",
    "        \"Manufacturer\": \"ANT Neuro\",\n",
    "        \"ManufacturersModelName\": \"EEG Cap: waveguard original cap (CA-203.s1). Amplifier: eego sports (EE-225).\",\n",
    "        \"TaskDescription\": \"\",\n",
    "        \"Instructions\": \"\",\n",
    "        \"EEGReference\": \"CPz\",\n",
    "        \"PowerLineFrequency\": 50,\n",
    "        \"SoftwareFilter\": \"n/a\",\n",
    "        \"RecordingType\": \"continuous\",\n",
    "        \"EEGGround\": \"left earlobe\",\n",
    "        \"EEGPlacementScheme\": \"10-5\"\n",
    "    }\n",
    "    '''\n",
    "    if switch_task == 1:\n",
    "        tInfo[\"TaskDescription\"] = \"The P300 component was elicited in an active visual oddball task, adapted from the ERP Core (Kappenman et al., 2021). The letters A, B, C, D, and E were presented in random order (p = .2 for each letter). For each block one letter was designated the target and the other 4 letters were distracters. Each letter was a target in 2 blocks and a distractor in the other 8 blocks. Participants responded whether the presented letter was the target or a distracter on each trial. Target-response mappings were randomized.\"\n",
    "        tInfo[\"Instructions\"] = \"Throughout this experiment you will see a stream of letters (ABCDE). Your task is to respond to the letter that was displayed by pressing either the [TARGET_BUTTON] or [DISTRACTER_BUTTON], depending on the assignment given at the beginning of each block. You can take pauses between blocks if required. Press the buttons with your left and right index fingers. Maintain fixation on the cross in the screen center. Respond as quickly and accurately as possible.\"\n",
    "    elif switch_task == 2:\n",
    "        tInfo[\"TaskDescription\"] = \"The N170 component was elicited in an active visual distracter task. Images of neutral faces, taken from the Chicago Face Database (Ma et al., 2015) were presented in random order. Subjects fixated a fixation cross in the screen center and responded when a red dot (=distracter) flickered in the center of the fixation cross. Distracters (p = .1 for each image) were spaced by at least 4 s.\"\n",
    "        tInfo[\"Instructions\"] = \"During this experiment faces will be presented, either without or with small breaks in between. Your task is to fixate the cross in the screen center and press the [BUTTON], as soon as you see a red dot flickering in the center of the cross. You can take pauses between blocks if required. Press the [BUTTON] with your right index finger. Respond as quickly as possible.\"\n",
    "    '''\n",
    "    file = file_path + '/eeg.json'\n",
    "    with open(file, \"w\") as json_file:\n",
    "        json.dump(tInfo, json_file, indent=4)\n",
    "        return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbb300c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_events_json(file_path):\n",
    "\n",
    "    eInfo = {\n",
    "        'onset': 'latency',\n",
    "        'duration': 'duration',\n",
    "        'sample': 'latency',\n",
    "        'trial_type': 'type',\n",
    "        'response_time': 'response_time',\n",
    "        'keycode': 'keycode',\n",
    "        'target_response': 'target_response'\n",
    "    }\n",
    "    \n",
    "    eInfoDesc = {\n",
    "        'keycode': {\n",
    "            'Description': 'Keycode for response',\n",
    "            'Levels': {\n",
    "                'left': '11',\n",
    "                'right': '12'\n",
    "            }\n",
    "        },\n",
    "        'target_response': {\n",
    "            'Description': 'Target-response mapping',\n",
    "            'Levels': {\n",
    "                'left': 'Left response (=keycode: 11) is correct for target trials with target_response=left',\n",
    "                'right': 'Right response (=keycode: 12) is correct for target trials with target_response=right'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        'eInfo': eInfo,\n",
    "        'eInfoDesc': eInfoDesc\n",
    "    }\n",
    "    file = file_path + '/events.json'\n",
    "    \n",
    "    with open(file, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "        return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7396075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_description_json(file_path):\n",
    "    general_info = {\n",
    "        'Name': 'P300 visual oddball task + N170 visual distracter task',\n",
    "        'ReferencesAndLinks': ['No bibliographic reference other than the DOI for this dataset'],\n",
    "        'BIDSVersion': 'v1.7.0',\n",
    "        'License': 'CC-BY',\n",
    "        'Authors': ['Martin Geiger']\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'general_info': general_info\n",
    "    }\n",
    "\n",
    "    file = file_path + '/dataset_description.json'\n",
    "    with open(file, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b6ede5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_participants_tsv(file_path):\n",
    "    pInfo = [\n",
    "        ['gender', 'age', 'handedness', 'vision'],\n",
    "        ['M', 25, 'R', 'N'],\n",
    "        ['M', 26, 'R', 'N'],\n",
    "        ['M', 29, 'R', 'C'],\n",
    "        ['M', 27, 'R', 'C'],\n",
    "        ['F', 29, 'R', 'N'],\n",
    "        ['M', 36, 'R', 'N'],\n",
    "        ['M', 28, 'R', 'C'],\n",
    "        ['M', 30, 'R', 'N'],\n",
    "        ['M', 27, 'R', 'N'],\n",
    "        ['M', 23, 'R', 'N'],\n",
    "        ['F', 26, 'R', 'C'],\n",
    "        ['F', 28, 'R', 'C'],\n",
    "        ['M', 30, 'R', 'N'],\n",
    "        ['M', 34, 'R', 'C'],\n",
    "        ['M', 24, 'R', 'C'],\n",
    "        ['M', 29, 'R', 'N'],\n",
    "        ['F', 26, 'R', 'C'],\n",
    "        ['M', 30, 'R', 'N'],\n",
    "        ['F', 30, 'R', 'N'],\n",
    "        ['M', 28, 'R', 'N'],\n",
    "        ['M', 26, 'R', 'N'],\n",
    "        ['F', 21, 'R', 'N'],\n",
    "        ['M', 32, 'R', 'N'],\n",
    "        ['M', 26, 'R', 'C'],\n",
    "        ['M', 30, 'R', 'C'],\n",
    "        ['M', 28, 'R', 'N'],\n",
    "        ['M', 27, 'R', 'N'],\n",
    "        ['W', 29, 'R', 'N'],\n",
    "        ['M', 23, 'R', 'C'],\n",
    "        ['F', 25, 'R', 'C'],\n",
    "        ['M', 30, 'R', 'N'],\n",
    "        ['F', 27, 'R', 'N'],\n",
    "        ['M', 33, 'R', 'C'],\n",
    "        ['F', 24, 'R', 'N'],\n",
    "        ['F', 25, 'R', 'N'],\n",
    "        ['M', 27, 'R', 'N'],\n",
    "        ['F', 22, 'R', 'N'],\n",
    "        ['F', 25, 'R', 'N'],\n",
    "        ['M', 22, 'R', 'N'],\n",
    "        ['F', 23, 'R', 'N'],\n",
    "        ['M', 23, 'R', 'N']\n",
    "    ]\n",
    "    file = file_path + '/participants.tsv'\n",
    "    with open(file, 'w', newline='') as tsv_file:\n",
    "        writer = csv.writer(tsv_file, delimiter='\\t')\n",
    "        writer.writerows(pInfo)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c2ecda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_file_name(output_dir,file_prefix,ext):\n",
    "     return os.path.join(output_dir, file_prefix + ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "036c05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bids_files(xdf_file, output_dir, participants_file, events_file, dataset_desc_file, eeg_desc_file, participants_desc_file):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Generate EEG file paths\n",
    "    xdf_file_prefix = os.path.splitext(os.path.basename(xdf_file))[0]\n",
    "    vhdr_file = gen_file_name(output_bids,xdf_file_prefix,'.vhdr')\n",
    "    vmrk_file = gen_file_name(output_bids,xdf_file_prefix,'.vmrk')\n",
    "    eeg_file = gen_file_name(output_bids,xdf_file_prefix,'.eeg')\n",
    "    # Create .vhdr file\n",
    "    with open(vhdr_file, 'w') as file:\n",
    "        file.write(f'Brain Vision Data Exchange Header File Version 1.0\\n')\n",
    "\n",
    "\n",
    "    # Create .vmrk file\n",
    "    with open(vmrk_file, 'w') as file:\n",
    "        file.write(f'Brain Vision Data Exchange Marker File Version 1.0\\n')\n",
    "       \n",
    "\n",
    "    # Create .eeg file (empty file)\n",
    "    open(eeg_file, 'a').close()\n",
    "\n",
    "    # Copy participants.tsv file\n",
    "    participants_output_file = os.path.join(output_dir, 'participants.tsv')\n",
    "    os.replace(participants_file, participants_output_file)\n",
    "\n",
    "    # Copy events.json file\n",
    "    events_output_file = os.path.join(output_dir, 'events.json')\n",
    "    os.replace(events_file, events_output_file)\n",
    "\n",
    "    # Copy dataset_description.json file\n",
    "    dataset_desc_output_file = os.path.join(output_dir, 'dataset_description.json')\n",
    "    os.replace(dataset_desc_file, dataset_desc_output_file)\n",
    "\n",
    "    # Copy eeg.json file\n",
    "    eeg_desc_output_file = os.path.join(output_dir, 'eeg.json')\n",
    "    os.replace(eeg_desc_file, eeg_desc_output_file)\n",
    "\n",
    "    # Copy participants.json file\n",
    "    participants_desc_output_file = os.path.join(output_dir, 'participants.json')\n",
    "    os.replace(participants_desc_file, participants_desc_output_file)\n",
    "\n",
    "    return vhdr_file, vmrk_file, eeg_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80eba21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_bids_files(bids_dir):\n",
    "    # write a validator function\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8deceea",
   "metadata": {},
   "source": [
    "#### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6801be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for new files\n",
    "# The path is in the sub-xxx/ses-xxx structure.\n",
    "PATH = 'xdf_files/'\n",
    "last_checked_file_path = 'last_time_checked.txt'\n",
    "check_for_new_file(PATH, last_checked_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f70f142d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=65, n_times=923008\n",
      "    Range : 0 ... 923007 =      0.000 ...   922.999 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "xdf_file = 'sample_data/raw_xdf/sub-004/ses-001/eeg/sub-004_ses-001_task-Duration_run-001_eeg.xdf'\n",
    "stream_names,streams = get_the_streams(xdf_file)\n",
    "raw = create_raw_xdf(xdf_file,streams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f95d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the metadata files\n",
    "file_path = 'metadata_bids' # add file path for main function\n",
    "part_desc_file = create_participants_json(file_path)\n",
    "\n",
    "eeg_desc_file = create_eeg_json(file_path)\n",
    "\n",
    "events_file = create_events_json(file_path)\n",
    "\n",
    "dataset_desc_file = create_dataset_description_json(file_path)\n",
    "\n",
    "participants_file = create_participants_tsv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68f38004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created BIDS files: test_bids_dir/sub-004_ses-001_task-Duration_run-001_eeg.vhdr, test_bids_dir/sub-004_ses-001_task-Duration_run-001_eeg.vmrk, test_bids_dir/sub-004_ses-001_task-Duration_run-001_eeg.eeg\n"
     ]
    }
   ],
   "source": [
    "# create BIDS directory\n",
    "output_bids = 'test_bids_dir'\n",
    "vhdr_file, vmrk_file, eeg_file = create_bids_files(xdf_file,output_bids, participants_file, events_file, dataset_desc_file, eeg_desc_file, part_desc_file)\n",
    "\n",
    "print(f'Created BIDS files: {vhdr_file}, {vmrk_file}, {eeg_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a65a400e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_bids_files(output_bids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45cd272",
   "metadata": {},
   "source": [
    "##### TODO \n",
    " https://github.com/cbrnr/bci_event_2021\n",
    " .bidsignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf5c595",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "542e11ce8348d7613f33131bef28ea92c5fa2eacace1df570018335ea87af401"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
